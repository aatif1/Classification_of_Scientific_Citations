<?xml version="1.0" encoding="iso-8859-1"?>
<acldoc acl_id="P04-1048">
	

	<s id="1">
		 Inducing Frame Semantic Verb Classes from WordNet and LDOCE Rebecca Green,*†‡ Bonnie J. Dorr,*† and Philip Resnik*† Institute for Advanced Computer Studies † Department of Computer Science College of Information Studies University of Maryland College Park , MD 20742 USA { rgreen , bonnie , resnik}@umiacs.umd.edu * ‡ Abstract This paper presents SemFrame , a system that induces frame semantic verb classes from WordNet and LDOCE . 
	</s>
	

	<s id="2">
		 Semantic frames are thought to have significant potential in resolving the paraphrase problem challenging many language- based applications . 
	</s>
	

	<s id="3">
		 When compared to the handcrafted FrameNet , SemFrame achieves its best recall-precision balance with 83.2 % recall ( based on SemFrame 's coverage of FrameNet frames ) and 73.8 % precision ( based on SemFrame verbs’ semantic relatedness to frame-evoking verbs ) . 
	</s>
	

	<s id="4">
		 The next best performing semantic verb classes achieve 56.9 % recall and 55.0 % precision . 
	</s>
	

	<s id="5">
		 1 Introduction Semantic content can almost always be expressed in a variety of ways . 
	</s>
	

	<s id="6">
		 Lexical synonymy ( She esteemed him highly vs. . 
	</s>
	

	<s id="7">
		 She respected him greatly ) , syntactic variation ( John paid the bill vs. . 
	</s>
	

	<s id="8">
		 The bill was paid by John ) , overlapping meanings ( Anna turned at Elm vs. Anna rounded the corner at Elm ) , and other phenomena interact to produce a broad range of choices for most language generation tasks 
		<ref citStr="Hirst , 2003" id="1" label="CEPF" position="1429">
			( Hirst , 2003 
		</ref>
		<ref citStr="Rinaldi et al. , 2003" id="2" label="CEPF" position="1444">
			; Rinaldi et al. , 2003 
		</ref>
		<ref citStr="Kozlowski et al. , 2003" id="3" label="CEPF" position="1468">
			; Kozlowski et al. , 2003 )
		</ref>
		 . 
	</s>
	

	<s id="9">
		 At the same time , natural language understanding must recognize what remains constant across paraphrases . 
	</s>
	

	<s id="10">
		 The paraphrase phenomenon affects many computational linguistic applications , including information retrieval , information extraction , question-answering , and machine translation . 
	</s>
	

	<s id="11">
		 For example , documents that express the same content using different linguistic means should typically be retrieved for the same queries . 
	</s>
	

	<s id="12">
		 Information sought to answer a question needs to be recognized no matter how it is expressed . 
	</s>
	

	<s id="13">
		 Semantic frames 
		<ref citStr="Fillmore , 1982" id="4" label="CEPF" position="2087">
			( Fillmore , 1982 
		</ref>
		<ref citStr="Fillmore and Atkins , 1992" id="5" label="CEPF" position="2105">
			; Fillmore and Atkins , 1992 )
		</ref>
		 address the paraphrase problem through their slot-and-filler templates , representing frequently occurring , structured experiences . 
	</s>
	

	<s id="14">
		 Semantic frame types of an intermediate granularity have the potential to fulfill an interlingua role within a solution to the paraphrase problem . 
	</s>
	

	<s id="15">
		 Until now , semantic frames have been generated by hand ( as in Fillmore and Atkins , 1992 ) , based on native speaker intuition ; the FrameNet project ( http://www.icsi.berkeley.edu/ —framenet ; Johnson et al. , 2002 ) now couples this generation with empirical validation . 
	</s>
	

	<s id="16">
		 Only recently has this project begun to achieve relative breadth in its inventory of semantic frames . 
	</s>
	

	<s id="17">
		 To have a comprehensive inventory of semantic frames , however , we need the capacity to generate semantic frames semi-automatically ( the need for manual post-editing is assumed ) . 
	</s>
	

	<s id="18">
		 To address these challenges , we have developed SemFrame , a system that induces semantic frames automatically . 
	</s>
	

	<s id="19">
		 Overall , the system performs two primary functions : ( 1 ) identification of sets of verb senses that evoke a common semantic frame ( in the sense that lexical units call forth corresponding conceptual structures ) ; and ( 2 ) identification of the conceptual structure of semantic frames . 
	</s>
	

	<s id="20">
		 This paper explores the first task of identifying frame semantic verb classes . 
	</s>
	

	<s id="21">
		 These classes have several types of uses . 
	</s>
	

	<s id="22">
		 First , they are the basis for identifying the internal structure of the frame proper , as set forth in Green and Dorr , 2004 . 
	</s>
	

	<s id="23">
		 Second , they may be used to extend FrameNet . 
	</s>
	

	<s id="24">
		 Third , they support applications needing access to sets of semantically related words , for example , text segmentation and word sense disambiguation , as explored to a limited degree in Green , 2004 . 
	</s>
	

	<s id="25">
		 Section 2 presents related research efforts on developing semantic verb classes . 
	</s>
	

	<s id="26">
		 Section 3 summarizes the features of WordNet ( http://www.cogsci.princeton.edu/—wn ) and LDOCE 
		<ref citStr="Procter , 1978" id="6" label="CEPF" position="4200">
			( Procter , 1978 )
		</ref>
		 that support the automatic induction of semantic verb classes , definitions and example sentences often mention while Section 4 sets forth the approach taken by their participants using semantic-type-like nouns , SemFrame to accomplish this task . 
	</s>
	

	<s id="27">
		 Section 5 thus mapping easily to the corresponding frame presents a brief synopsis of SemFrame’s results , element . 
	</s>
	

	<s id="28">
		 Corpus data , however , are more likely while Section 6 presents an evaluation of to include instantiated participants , which may SemFrame’s ability to identify semantic verb not generalize to the frame element . 
	</s>
	

	<s id="29">
		 Second , classes of a FrameNet-like nature . 
	</s>
	

	<s id="30">
		 Section 7 lexical resources provide a consistent amount of summarizes our work and motivates directions for data for word senses , while the amount of data in further development of SemFrame . 
	</s>
	

	<s id="31">
		 a corpus for word senses is likely to vary widely . 
	</s>
	

	<s id="32">
		 2 Previous Work The EAGLES ( 1998 ) report on semantic encoding differentiates between two approaches to the development of semantic verb classes : those based on syntactic behavior and those based on semantic criteria . 
	</s>
	

	<s id="33">
		 
		<ref citStr="Levin ( 1993 )" id="7" label="CEPF" position="5370">
			Levin ( 1993 )
		</ref>
		 groups verbs based on an analysis of their syntactic properties , especially their ability to be expressed in diathesis alternations ; her approach reflects the assumption that the syntactic behavior of a verb is determined in large part by its meaning . 
	</s>
	

	<s id="34">
		 Verb classes at the bottom of Levin’s shallow network group together ( quasi- ) synonyms , hierarchically related verbs , and antonyms , alongside verbs with looser semantic relationships . 
	</s>
	

	<s id="35">
		 The verb categories based on 
		<ref citStr="Pantel and Lin ( 2002 )" id="8" label="CEPF" position="5887">
			Pantel and Lin ( 2002 )
		</ref>
		 and 
		<ref citStr="Lin and Pantel ( 2001 )" id="9" label="CEPF" position="5915">
			Lin and Pantel ( 2001 )
		</ref>
		 are induced automatically from a large corpus , using an unsupervised clustering algorithm , based on syntactic dependency features . 
	</s>
	

	<s id="36">
		 The resulting clusters contain synonyms , hierarchically related verbs , and antonyms , as well as verbs more loosely related from the perspective of paraphrase . 
	</s>
	

	<s id="37">
		 The handcrafted WordNet 
		<ref citStr="Fellbaum , 1998a" id="10" label="OEPF" position="6275">
			( Fellbaum , 1998a )
		</ref>
		 uses the hyperonymy/hyponymy relationship to structure the English verb lexicon into a semantic network . 
	</s>
	

	<s id="38">
		 Each collection of a top-level node supplemented by its descendants may be seen as a semantic verb class . 
	</s>
	

	<s id="39">
		 In all fairness , resolution of the paraphrase problem is not the explicit goal of most efforts to build semantic verb classes . 
	</s>
	

	<s id="40">
		 However , they can process some paraphrases through lexical synonymy , hierarchically related terms , and antonymy . 
	</s>
	

	<s id="41">
		 3 Resources Used in SemFrame We adopt an approach that relies heavily on pre-existing lexical resources . 
	</s>
	

	<s id="42">
		 Such resources have several advantages over corpus data in identifying semantic frames . 
	</s>
	

	<s id="43">
		 First , both Third , lexical resources provide their data in a more systematic fashion than do corpora . 
	</s>
	

	<s id="44">
		 Most centrally , the syntactic arguments of the verbs used in a definition often correspond to the semantic arguments of the verb being defined . 
	</s>
	

	<s id="45">
		 For example , Table 1 gives the definitions of several verb senses in LDOCE that evoke the COMMERCIAL TRANSACTION frame , which includes as its semantic arguments a Buyer , a Seller , some Merchandise , and Money . 
	</s>
	

	<s id="46">
		 Words corresponding to the Money ( money , value ) , the Merchandise ( property , goods ) , and the Buyer ( buyer , buyers ) are present in , and to some extent shared across , the definitions ; however , no words corresponding to the Seller are present . 
	</s>
	

	<s id="47">
		 Verb sense LDOCE Definition buy 1 to obtain ( something ) by giving money ( or something else of value ) buy 2 to obtain in exchange for something , often something of great value buy 3 to be exchangeable for purchase 1 to gain ( something ) at the cost of effort , suffering , or loss of something of value sell 1 to give up ( property or goods ) to another for money or other value sell 2 to offer ( goods ) for sale sell 3 to be bought ; get a buyer or buyers ; gain a sale Table 1 . 
	</s>
	

	<s id="48">
		 LDOCE Definitions for Verbs Evoking the COMMERCIAL TRANSACTION Frame Of available machine-readable dictionaries , LDOCE appears especially useful for this research . 
	</s>
	

	<s id="49">
		 It uses a restricted vocabulary of about 2000 words in its definitions and example sentences , thus increasing the likelihood that words with closely related meanings will use the same words in their definitions and support WordNet verb synsets and LDOCE verb senses the pattern of discovery envisioned . 
	</s>
	

	<s id="50">
		 LDOCE’s relies on finding matches between the data subject field codes also accomplish some of the available for the verb senses in each resource same type of grouping as semantic frames . 
	</s>
	

	<s id="51">
		 ( e.g. , other words in the synset ; words in WordNet is a machine-readable lexico- definitions and example sentences ; words closely semantic database whose primary organizational related to these words ; and stems of these words ) . 
	</s>
	

	<s id="52">
		 structure is the synset—a set of synonymous word The similarity measure used is the average of the senses . 
	</s>
	

	<s id="53">
		 A limited number of relationship types proportion of words on each side of the ( e.g. , antonymy , hyponymy , meronymy , comparison that are matched in the other . 
	</s>
	

	<s id="54">
		 This troponymy , entailment ) also relate synsets within mapping is used both to relate LDOCE verb senses , a part of speech . 
	</s>
	

	<s id="55">
		 ( Version 1.7.1 was used . 
	</s>
	

	<s id="56">
		 ) that map to the same WordNet synset ( fig . 
	</s>
	

	<s id="57">
		 3f ) and to 
		<ref citStr="Fellbaum ( 1998b )" id="11" label="CEPF" position="9718">
			Fellbaum ( 1998b )
		</ref>
		 suggests that relationships translate previously paired WordNet verb synsets in WordNet “reflect some of the structure of into LDOCE verb sense pairs . 
	</s>
	

	<s id="58">
		 frame semantics” ( p. 5 ) . 
	</s>
	

	<s id="59">
		 Through the relational In the third stage , the resulting verb sense structure of WordNet , buy , purchase , sell , and pay pairs are merged into a single data set , retaining are related together : buy and purchase comprise one only those pairs whose cumulative support synset ; they entail paying and are opposed to sell . 
	</s>
	

	<s id="60">
		 exceeds thresholds for either the number of The relationship of buy , purchase , sell , and supporting data sources or strength of support , pay to other COMMERCIAL TRANSACTION thus achieving higher precision in the merged verbs—for example , cost , price , and the demand data set than in the input data sets . 
	</s>
	

	<s id="61">
		 Then , the payment sense of charge—is not made explicit in graph formed by the verb sense pairs in the WordNet , however . 
	</s>
	

	<s id="62">
		 Further , as Roger Chaffin merged data set is analyzed to find the fully has noted , the specialized vocabulary of , for connected components . 
	</s>
	

	<s id="63">
		 example , tennis ( e.g. racket , court , lob ) is not co- Finally , these groups of verb senses become located , but is dispersed across different branches input to a clustering operation 
		<ref citStr="Voorhees , 1986" id="12" label="CEPF" position="11068">
			( Voorhees , 1986 )
		</ref>
		 . 
	</s>
	

	<s id="64">
		 of the noun network ( Miller , 1998 , p. 34 ) . 
	</s>
	

	<s id="65">
		 Those groups whose similarity ( due to overlap in 4 SemFrame Approach SemFrame gathers evidence about frame semantic relatedness between verb senses by analyzing LDOCE and WordNet data from a variety of perspectives . 
	</s>
	

	<s id="66">
		 The overall approach used is shown in Figure 1 . 
	</s>
	

	<s id="67">
		 The first stage of processing extracts pairs of LDOCE and WordNet verb senses that potentially evoke the same frame . 
	</s>
	

	<s id="68">
		 By exploiting many different clues to semantic relatedness , we overgenerate these pairs , favoring recall ; subsequent stages improve the precision of the resulting data . 
	</s>
	

	<s id="69">
		 Figures 2 and 3 give details of the algorithms for extracting verb pairs based on different types of evidence . 
	</s>
	

	<s id="70">
		 These include : clustering LDOCE verb senses/WordNet synsets on the basis of words in their definitions and example sentences ( fig . 
	</s>
	

	<s id="71">
		 2 ) ; relating LDOCE verb senses defined in terms of the same verb ( fig . 
	</s>
	

	<s id="72">
		 3a ) ; relating LDOCE verb senses that share a common stem ( fig . 
	</s>
	

	<s id="73">
		 3b ) ; extracting explicit sense-linking relationships in LDOCE ( fig . 
	</s>
	

	<s id="74">
		 3c ) ; relating verb senses that share general or specific subject field codes in LDOCE ( fig . 
	</s>
	

	<s id="75">
		 3d ) ; and extracting ( direct or extended ) semantic relationships in WordNet ( fig . 
	</s>
	

	<s id="76">
		 3e ) . 
	</s>
	

	<s id="77">
		 In the second stage , mapping between membership ) exceed a threshold are merged together , thus reducing the number of verb sense groups . 
	</s>
	

	<s id="78">
		 The verb senses within each resulting group are hypothesized to evoke the same semantic frame and constitute a frameset . 
	</s>
	

	<s id="79">
		 Extract verb sense pairs from WordNet Map WordNet synsets to LDOCE senses Merge pairs , filtering out those not meeting threshold criteria Build fully-connected verb groups Cluster related verb groups Verb sense framesets Figure 1 . 
	</s>
	

	<s id="80">
		 Approach for Building Frame Semantic Verb Classes Extract verb sense pairs from LDOCE Figure 2. Algorithm for Generating Clustering-based Verb Pairs 5 Results We explored a range of thresholds in the final stage of the algorithm.1 In general , the lower the threshold , the looser the verb grouping . 
	</s>
	

	<s id="81">
		 The number of verb senses retained ( out of 12,663 non-phrasal verb senses in LDOCE ) and the verb sense groups produced by using these thresholds are recorded in Table 2 . 
	</s>
	

	<s id="82">
		 6 Evaluation One of our goals is to produce sets of verb senses capable of extending FrameNet 's coverage while requiring reasonably little post-editing . 
	</s>
	

	<s id="83">
		 This goal has two subgoals : identifying new frames and identifying additional lexical units that evoke 1 Threshold Num verb senses Num groups 0.5 6461 1338 1.0 6414 1759 1.5 5607 1421 2.0 5604 1563 Table 2 . 
	</s>
	

	<s id="84">
		 Results of Frame Clustering Process previously recognized frames . 
	</s>
	

	<s id="85">
		 We use the handcrafted FrameNet , which is of reliably high precision , as a gold standar&amp; for the initial evaluation of SemFrame 's ability to achieve these subgoals . 
	</s>
	

	<s id="86">
		 For the first , we evaluate SemFrame’s ability to generate frames that correspond to FrameNet’s frames , reasoning that the system must be able to identify a large proportion of known frames if the quality of its output is good enough to identify new frames . 
	</s>
	

	<s id="87">
		 ( At this stage we do not measure the quality of new frames . 
	</s>
	

	<s id="88">
		 ) For the second subgoal we can be more concrete : For frames identified by both systems , we measure the degree to which the verbs identified by SemFrame can be shown to evoke those frames , even if FrameNet has not identified them as frame-evoking verbs . 
	</s>
	

	<s id="89">
		 FrameNet includes hierarchically organized frames of varying levels of generality : Some semantic areas are covered by a general frame , some by a combination of specific frames , and some by a mix of general and specific frames . 
	</s>
	

	<s id="90">
		 Because of this variation we determined the degree to which SemFrame and FrameNet overlap by automatically finding and comparing corresponding frames instead of fully equivalent frames . 
	</s>
	

	<s id="91">
		 Frames correspond if the semantic scope of one frame is included within the semantic 2Certain constraints imposed by FrameNet 's development strategy restrict its use as a full-fledged gold standard for evaluating semantic frame induction . 
	</s>
	

	<s id="92">
		 ( 1 ) As of summer 2003 , only 382 frames had been identified within the FrameNet project . 
	</s>
	

	<s id="93">
		 ( 2 ) Low recall affects not only the set of semantic frames identified by FrameNet , but also the sets of frame-evoking units listed for each frame . 
	</s>
	

	<s id="94">
		 No verbs are listed for 38.5 % of FrameNet 's frames , while another 13.1 % of them list only 1 or 2 verbs . 
	</s>
	

	<s id="95">
		 The comparison here is limited to the 197 FrameNet frames for which at least one verb is listed with a counterpart in LDOCE . 
	</s>
	

	<s id="96">
		 ( 3 ) Some of Input . 
	</s>
	

	<s id="97">
		 SW , a set of stop words ; M , a set of ( word , stem ) pairs ; F , a set of ( word , frequency ) pairs ; DE , a set of ( verb_sense_id , def+ex ) pairs , where def+exd = the set of words in the definitions and example sentences of verb_sense_idd Step 1. forall d E DE , append to def+exd : verb_sense_idd and remove from def+exd any word w E SW Step 2. forall d E DE forall . 
	</s>
	

	<s id="98">
		 E M if word . 
	</s>
	

	<s id="99">
		 exists in def+exd , substitute ste .. for word . 
	</s>
	

	<s id="100">
		 Step 3. forall f E F if frequencyf &gt; 1 , wgtwordf 1 frequency f , else if frequencyf == 1 , wgtwordf .01 Step 4 . 
	</s>
	

	<s id="101">
		 O Voorhees’ average link clustering algorithm applied to DE , with initial weights forall t in def+ex set to wgtt Step 5. forall o E O return all combinations of two members from o For the clustering algorithm used , the clustering FrameNet 's frames are more syntactically than threshold range is open-ended . 
	</s>
	

	<s id="102">
		 The values semantically motivated ( e.g. , EXPERIENCER-OBJECT , investigated in the evaluation are fairly low . 
	</s>
	

	<s id="103">
		 EXPERIENCER-SUBJECT ) . 
	</s>
	

	<s id="104">
		 a. Relates LDOCE verb senses that are defined in terms of the same verb Input . 
	</s>
	

	<s id="105">
		 D , a set of ( verb—sense—id , def—verb ) pairs , where def—verbd = the verb in terms of which verb—sense—idd is defined Step 1. forall v that exist as def—verb in D , form DVv c : D , by extracting all ( verb—sense—id , def—verb ) pairs where v = def—verb Step 2. remove all DVv for which | DVv | &gt; 40 Step 3. forall v that exist as def—verb in D , return all combinations of two members from DVv b. Relates LDOCE verb senses that share a common stem Input . 
	</s>
	

	<s id="106">
		 D , a set of ( verb—sense—id , verb—stem ) pairs , where verb—stemd = the stem for the verb on which verb—sense—idd is based Step 1. forall m that exist as verb—stem in D , form DVm c : D , by extracting all ( verb—sense—id , verb —stem ) pairs where m = verb—stem Step 2. forall m that exist as verb—stem in D , return all combinations of two members from DVv c . 
	</s>
	

	<s id="107">
		 Extracts explicit sense-linking relationships in LDOCE Input . 
	</s>
	

	<s id="108">
		 D , a set of ( verb—sense—id , def ) pairs , where defd = the definition for verb—sense—idd Step 1. forall d E D , if defd contains compare or opposite note , extract related—verb from note ; generate ( verb—sense—idd , related—verbd ) pair Step 2. forall d E D , if defd defines verb—sense—idd in terms of a related standalone verb ( in BLOCK CAPS ) , extract related—verb from definition ; generate ( verb—sense—idd , related—verbd ) pair Step 3. forall ( verb—sense—idd , related—verbd ) pairs , if there is only one sense of related—verbd , choose it and return ( verb—sense—idd , related—verb—sense—idd ) , else apply generalized mapping algorithm to return ( verb—sense—idd , related—verb—sense—idd ) pairs where overlap occurs in the glosses of verb—sense—idd and related—verb—sense—idd d. Relates verb senses that share general or specific subject field codes in LDOCE Input . 
	</s>
	

	<s id="109">
		 D , a set of ( verb—sense—id , subject—code ) pairs , where subject—coded = any 2- or 4-character subject field code assigned to verb—sense—id Step 1. forall c that exist as subject—code in D , form DVc c : D , by extracting all ( verb—sense—id , subject—code ) pairs where c = subject—code Step 2. forall c that exist as subject—code in D , return all combinations of two members from DVv e . 
	</s>
	

	<s id="110">
		 Extracts ( direct or extended ) semantic relationships in WordNet Input . 
	</s>
	

	<s id="111">
		 WordNet data file for verb synsets Step 1. forall synset lines in input file return ( synset , related —synset ) pairs for all synsets directly related through hyponymy , antonymy , entailment , or cause—to relationships in WordNet ( for extended relationship pairs , also return ( synset , related—synset ) pairs for all synsets within hyponymy tree , i.e. , no matter how many levels removed ) f. Relates LDOCE verb senses that map to the same WordNet synset Input . 
	</s>
	

	<s id="112">
		 mapping of LDOCE verb senses to WordNet synsets Step 1. forall lines in input file return all combinations of two LDOCE verb senses mapped to the same WordNetlsynset Figure 3. Algorithms for Generating Non-clustering-based Verb Pairs scope of the other frame or if the semantic scopes SemFrame’s verb classes list specific LDOCE of the two frames have significant overlap . 
	</s>
	

	<s id="113">
		 Since verb senses . 
	</s>
	

	<s id="114">
		 In extending FrameNet , verbs from FrameNet lists evoking words , without SemFrame would be word-sense-disambiguated specification of word sense , the comparison was in the same way that FrameNet verbs currently done on the word level rather than on the word are , through the correspondence of lexeme and sense level , as if LDOCE verb senses were not frame . 
	</s>
	

	<s id="115">
		 specified in SemFrame . 
	</s>
	

	<s id="116">
		 However , it is clearly Incompleteness in the listing of evoking verbs specific word senses that evoke frames , and in FrameNet and SemFrame precludes a straight- forward detection of correspondences between incrust , and ornament . 
	</s>
	

	<s id="117">
		 Two of the verbs—adorn their frames . 
	</s>
	

	<s id="118">
		 Instead , correspondence between and decorate—are shared . 
	</s>
	

	<s id="119">
		 In addition , the frame FrameNet and SemFrame frames is established names are semantically related through a using either of two somewhat indirect approaches . 
	</s>
	

	<s id="120">
		 WordNet synset consisting of decorate , adorn In the first approach , a SemFrame frame is ( which CatVar relates to ADORNING ) , grace , deemed to correspond to a FrameNet frame if the ornament ( which CatVar relates to two frames meet both a minimal-overlap ORNAMENTATION ) , embellish , and beautify . 
	</s>
	

	<s id="121">
		 The criterion ( i.e. , there is some , perhaps small , two frames are therefore designated as overlap between the FrameNet and SemFrame corresponding frames by meeting both the framesets ) and a frame-name-relatedness minimal-overlap and the frame-name relatedness criterion . 
	</s>
	

	<s id="122">
		 The minimal-overlap criterion is met if criteria . 
	</s>
	

	<s id="123">
		 either of two conditions is met : ( 1 ) If the In the second approach , a SemFrame frame is FrameNet frame lists four or fewer verbs ( true of deemed to correspond to a FrameNet frame if the over one-third of the FrameNet frames that list two frames meet either of two relatively stringent associated verbs ) , minimal overlap occurs when verb overlap criteria , the majority-match criterion any one verb associated with the FrameNet frame or the majority-related criterion , in which case matches a verb associated with a SemFrame examination of frame names is unnecessary . 
	</s>
	

	<s id="124">
		 frame . 
	</s>
	

	<s id="125">
		 ( 2 ) If the FrameNet frame lists five or The majority-match criterion is met if the set more verbs , minimal overlap occurs when two or of verbs shared by FrameNet and SemFrame more verbs in the FrameNet frame are matched by framesets account for half or more of the verbs in verbs in the SemFrame frame . 
	</s>
	

	<s id="126">
		 either frameset . 
	</s>
	

	<s id="127">
		 For example , the APPLY_HEAT The looseness of the minimal overlap frame in FrameNet includes 22 verbs : bake , criterion is tightened by also requiring that the blanch , boil , braise , broil , brown , char , coddle , names of the FrameNet and SemFrame frames be cook , fry , grill , microwave , parboil , poach , roast , closely related . 
	</s>
	

	<s id="128">
		 Establishing this frame-name saute , scald , simmer , steam , steep , stew , and relatedness involves identifying individual toast , while the BOILING frame in SemFrame components of each frame name ' and augmenting includes 7 verbs : boil , coddle , jug , parboil , this set with morphological variants from CatVar poach , seethe , and simmer . 
	</s>
	

	<s id="129">
		 Five of these 
		<ref citStr="Habash and Dorr 2003" id="13" label="CEPF" position="23642">
			( Habash and Dorr 2003 )
		</ref>
		 . 
	</s>
	

	<s id="130">
		 The resulting set for verbs—boil , coddle , parboil , poach , and each FrameNet and SemFrame frame name is simmer—are shared across the two frames and then searched in both the noun and verb WordNet constitute over half of the SemFrame frameset . 
	</s>
	

	<s id="131">
		 networks to find all the synsets that might Therefore the two frames are deemed to correspond to the frame name . 
	</s>
	

	<s id="132">
		 To these sets are correspond by meeting the majority-match also added all synsets directly related to the criterion . 
	</s>
	

	<s id="133">
		 synsets corresponding to the frame names . 
	</s>
	

	<s id="134">
		 If the The majority-related criterion is met if half or resulting set of synsets gathered for a FrameNet more of the verbs from the SemFrame frame are frame name intersects with the set of synsets semantically related to verbs from the FrameNet gathered for a SemFrame frame name , the two frame ( that is , if the precision of the SemFrame frame names are deemed to be semantically verb set is at least 0.5 ) . 
	</s>
	

	<s id="135">
		 To evaluate this criterion , related . 
	</s>
	

	<s id="136">
		 each FrameNet and SemFrame verb is associated For example , the FrameNet ADORNING frame with the WordNet verb synsets it occurs in , contains 17 verbs : adorn , blanket , cloak , coat , augmented by the synsets to which the initial sets cover , deck , decorate , dot , encircle , envelop , of synsets are directly related . 
	</s>
	

	<s id="137">
		 If the sets of festoon , fill , film , line , pave , stud , and wreathe . 
	</s>
	

	<s id="138">
		 synsets corresponding to two verbs share one or The SemFrame ORNAMENTATION frame contains more synsets , the two verbs are deemed to be 12 verbs : adorn , caparison , decorate , embellish , semantically related . 
	</s>
	

	<s id="139">
		 This process is extended embroider , garland , garnish , gild , grace , hang , one further level , such that a SemFrame verb found by this process to be semantically related to a SemFrame verb , whose semantic relationship to ' a FrameNet verb has already been established , will also be designated a frame-evoking verb . 
	</s>
	

	<s id="140">
		 If half or more of the verbs listed for a SemFrame frame are established as evoking the same frame as the list of WordNet verbs , then the FrameNet All SemFrame frame names are nouns . 
	</s>
	

	<s id="141">
		 ( See Green and Dorr , 2004 for an explanation of their selection . 
	</s>
	

	<s id="142">
		 ) FrameNet frame names ( e.g. , ABUNDANCE , ACTIVITY_START , CAUSE_TO_BE_WET , INCHOATIVE_ATTACHING ) , however , exhibit considerable variation . 
	</s>
	

	<s id="143">
		 and SemFrame frames are hypothesized to bound on the task , i.e. , 100 % recall and 100 % correspond through the majority-related criterion . 
	</s>
	

	<s id="144">
		 precision . 
	</s>
	

	<s id="145">
		 The Lin &amp; Pantel results are here a For example , the FrameNet ABUNDANCE lower bound for automatically induced semantic frame includes 4 verbs : crawl , swarm , teem , and verb classes and probably reflect the limitations of throng . 
	</s>
	

	<s id="146">
		 The SemFrame FLOW frame likewise using only corpus data . 
	</s>
	

	<s id="147">
		 Among efforts to develop includes 4 verbs : pour , teem , stream , and semantic verb classes , SemFrame’s results pullulate . 
	</s>
	

	<s id="148">
		 Only one verb—teem—is shared , so correspond more closely to semantic frames than the majority-match criterion is not met , nor is the do others . 
	</s>
	

	<s id="149">
		 related-frame-name criterion met , as the frame names are not semantically related . 
	</s>
	

	<s id="150">
		 The majority- related criterion , however , is met through a WordNet verb synset that includes pour , swarm , stream , teem , and pullulate . 
	</s>
	

	<s id="151">
		 Of the 197 FrameNet frames that include at least one LDOCE verb , 175 were found to have a corresponding SemFrame frame . 
	</s>
	

	<s id="152">
		 But this 88.8 % recall level should be balanced against the precision ratio of SemFrame verb framesets . 
	</s>
	

	<s id="153">
		 After all , we could get 100 % recall by listing all verbs in every SemFrame frame . 
	</s>
	

	<s id="154">
		 The majority-related function computes the precision ratio of the SemFrame frame for each pair of FrameNet and SemFrame frames being compared . 
	</s>
	

	<s id="155">
		 By modifying the minimum precision threshold , the balance between recall and precision , as measured using F-score , can be investigated . 
	</s>
	

	<s id="156">
		 The best balance for the SemFrame version is based on a clustering threshold of 2.0 and a minimum precision threshold of 0.4 , which yields a recall of 83.2 % and overall precision of 73.8 % . 
	</s>
	

	<s id="157">
		 To interpret these results meaningfully , one would like to know if SemFrame achieves more FrameNet-like results than do other available verb category data , more specifically the 258 verb classes from Levin , the 357 semantic verb classes of WordNet 1.7.1 , or the 272 verb clusters of Lin and Pantel , as described in Section 2 . 
	</s>
	

	<s id="158">
		 For purposes of comparison with FrameNet , Levin’s verb class names have been hand-edited to isolate the word that best captures the semantic sense of the class ; the name of a WordNet-based frame is taken from the words for the root-level synset ; and the name of each Lin and Pantel cluster is taken to be the first verb in the cluster.4 Evaluation results for the best balance between recall and precision ( i.e. , the maximum F-score ) of the four comparisons are summarized in Table 3 . 
	</s>
	

	<s id="159">
		 FrameNet itself constitutes the upper 4Lin and Pantel have taken a similar approach , “naming” their verb clusters by the first three verbs listed for a cluster , i.e. , the three most similar verbs . 
	</s>
	

	<s id="160">
		 Semantic verb classes Precision threshold at max F- Recall Precision score SemFrame 0.40 0.832 0.738 Levin 0.20 0.569 0.550 WordNet 0.15 0.528 0.466 Lin &amp; Pantel 0.15 0.472 0.407 Table 3 . 
	</s>
	

	<s id="161">
		 Best Recall-Precision Balance When Compared with FrameNet 7 Conclusions and Future Work We have demonstrated that sets of verbs evoking a common semantic frame can be induced from existing lexical tools . 
	</s>
	

	<s id="162">
		 In a head-to-head comparison with frames in FrameNet , the frame semantic verb classes developed by the SemFrame approach achieve a recall of 83.2 % and the verbs listed for frames achieve a precision of 73.8 % ; these results far outpace those of other semantic verb classes . 
	</s>
	

	<s id="163">
		 On a practical level , a large number of frame semantic verb classes have been identified . 
	</s>
	

	<s id="164">
		 Associated with clustering threshold 1.5 are 1421 verb classes , averaging 14.1 WordNet verb synsets . 
	</s>
	

	<s id="165">
		 Associated with clustering threshold 2.0 are 1563 verb classes , averaging 6.6 WordNet verb synsets . 
	</s>
	

	<s id="166">
		 Despite these promising results , we are limited by the scope of our input data set . 
	</s>
	

	<s id="167">
		 While LDOCE and WordNet data are generally of high quality , the relative sparseness of these resources has an adverse impact on recall . 
	</s>
	

	<s id="168">
		 In addition , the mapping technique used for picking out corresponding word senses in WordNet and LDOCE is shallow , thus constraining the recall and precision of SemFrame outputs . 
	</s>
	

	<s id="169">
		 Finally , the multi-step process of merging smaller verb groups into verb groups that are intended to correspond to frames sometimes fails to achieve an appropriate degree of correspondence ( all the verb classes discovered are not distinct ) . 
	</s>
	

	<s id="170">
		 In our future work , we will experiment with the more recent release of WordNet ( 2.0 ) . 
	</s>
	

	<s id="171">
		 This version provides derivational morphology links between nouns and verbs , which will promote far greater precision in the linking of verb senses based on morphology than was possible in our initial implementation . 
	</s>
	

	<s id="172">
		 Another significant addition to WordNet 2.0 is the inclusion of category domains , which co-locate words pertaining to a subject and perform the same function as LDOCE 's subject field codes . 
	</s>
	

	<s id="173">
		 Finally , data sparseness issues may be addressed by supplementing the use of the lexical resources used here with access to , for example , the British National Corpus , with its broad coverage and carefully-checked parse trees . 
	</s>
	

	<s id="174">
		 Acknowledgments This research has been supported in part by a National Science Foundation Graduate Research Fellowship NSF ITR grant #IIS-0326553 , and NSF CISE Research Infrastructure Award EIA0130422 . 
	</s>
	

	<s id="175">
		 References Boguraev , Bran and Ted Briscoe . 
	</s>
	

	<s id="176">
		 1989. Introduction . 
	</s>
	

	<s id="177">
		 In B. Boguraev and T. Briscoe ( Eds . 
	</s>
	

	<s id="178">
		 ) , Computational Lexicography for Natural Language Processing , 1- 40. London : Longman . 
	</s>
	

	<s id="179">
		 EAGLES Lexicon Interest Group . 
	</s>
	

	<s id="180">
		 1998. EAGLES Preliminary Recommendations on Semantic Encoding : Interim Report , &lt;http:// www.ilc.cnr.it/EAGLES96/rep2/ rep2.html&gt; . 
	</s>
	

	<s id="181">
		 Fellbaum , Christiane ( Ed . 
	</s>
	

	<s id="182">
		 1998a . 
	</s>
	

	<s id="183">
		 WordNet : An Electronic Lexical Database . 
	</s>
	

	<s id="184">
		 Cambridge , MA : The MIT Press . 
	</s>
	

	<s id="185">
		 Fellbaum , Christiane . 
	</s>
	

	<s id="186">
		 1998b . 
	</s>
	

	<s id="187">
		 Introduction . 
	</s>
	

	<s id="188">
		 In C. Fellbaum , 1998a , 1-17 . 
	</s>
	

	<s id="189">
		 Fillmore , Charles J. 1982 . 
	</s>
	

	<s id="190">
		 Frame semantics . 
	</s>
	

	<s id="191">
		 In Linguistics in the Morning Calm , 111-137 . 
	</s>
	

	<s id="192">
		 Seoul : Hanshin . 
	</s>
	

	<s id="193">
		 Fillmore , Charles J. and B. T. S. Atkins . 
	</s>
	

	<s id="194">
		 1992. Towards a frame-based lexicon : The semantics of RISK and its neighbors . 
	</s>
	

	<s id="195">
		 In A. Lehrer and E. F. Kittay ( Eds . 
	</s>
	

	<s id="196">
		 ) , Frames , Fields , and Contrasts , 75- 102 . 
	</s>
	

	<s id="197">
		 Hillsdale , NJ : Erlbaum . 
	</s>
	

	<s id="198">
		 Green , Rebecca . 
	</s>
	

	<s id="199">
		 2004. Inducing Semantic Frames from Lexical Resources . 
	</s>
	

	<s id="200">
		 Ph.D . 
	</s>
	

	<s id="201">
		 dissertation , University of Maryland . 
	</s>
	

	<s id="202">
		 Green , Rebecca and Bonnie J. Dorr . 
	</s>
	

	<s id="203">
		 2004. Inducing A Semantic Frame Lexicon from WordNet Data . 
	</s>
	

	<s id="204">
		 In Proceedings of the 2nd Workshop on Text Meaning and Interpretation ( ACL 2004 ) . 
	</s>
	

	<s id="205">
		 Habash , Nizar and Bonnie Dorr . 
	</s>
	

	<s id="206">
		 2003. A categorial variation database for English . 
	</s>
	

	<s id="207">
		 In Proceedings of North American Association for Computational Linguistics , 96-102 . 
	</s>
	

	<s id="208">
		 Hirst , Graeme . 
	</s>
	

	<s id="209">
		 2003 . 
	</s>
	

	<s id="210">
		 Paraphrasing paraphrased . 
	</s>
	

	<s id="211">
		 Keynote address for The Second International Workshop on Paraphrasing : Paraphrase Acquisition and Applications , ACL 2003 , &lt;http://nlp.nagaokaut.ac.jp/IWP2003/pdf/ Hirst-slides.pdf&gt; . 
	</s>
	

	<s id="212">
		 Johnson , Christopher R. , Charles J. Fillmore , Miriam R. L. Petruck , Collin F. Baker , Michael Ellsworth , Josef Ruppenhofer , and Esther J. Wood . 
	</s>
	

	<s id="213">
		 2002. FrameNet : Theory and Practice , version 1.0 , &lt;http://www.icsi.berkeley.edu/ ~framenet/book/book.html&gt; . 
	</s>
	

	<s id="214">
		 Kozlowski , Raymond , Kathleen F. McCoy , and K. Vijay-Shanker . 
	</s>
	

	<s id="215">
		 2003. Generation of single-sentence paraphrases from predicate/argument structure using lexico-grammatical resources . 
	</s>
	

	<s id="216">
		 In The Second International Workshop on Paraphrasing : Paraphrase Acquisition and Applications ( IWP2003 ) , ACL 2003 , 1-8 . 
	</s>
	

	<s id="217">
		 Levin , Beth . 
	</s>
	

	<s id="218">
		 1993. English Verb Classes and Alternations : A Preliminary Investigation . 
	</s>
	

	<s id="219">
		 Chicago : University of Chicago Press . 
	</s>
	

	<s id="220">
		 Lin , Dekang and Patrick Pantel . 
	</s>
	

	<s id="221">
		 2001 . 
	</s>
	

	<s id="222">
		 Induction of semantic classes from natural language text . 
	</s>
	

	<s id="223">
		 In Proceedings of ACM SIGKDD Conference on Knowledge Discovery and Data Mining , 317-322 . 
	</s>
	

	<s id="224">
		 Litkowski , Ken . 
	</s>
	

	<s id="225">
		 2004. Senseval-3 task : Word-sense disambiguation of WordNet glosses , &lt;http://www.clres.com/SensWNDisamb.html&gt; . 
	</s>
	

	<s id="226">
		 Miller , George A. 1998 . 
	</s>
	

	<s id="227">
		 Nouns in WordNet . 
	</s>
	

	<s id="228">
		 In C. Fellbaum , 1998a , 23-67 . 
	</s>
	

	<s id="229">
		 Pantel , Patrick and Dekang Lin . 
	</s>
	

	<s id="230">
		 2002 . 
	</s>
	

	<s id="231">
		 Discovering word senses from text . 
	</s>
	

	<s id="232">
		 In Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , 613- 619 . 
	</s>
	

	<s id="233">
		 Procter , Paul ( Ed . 
	</s>
	

	<s id="234">
		 1978. Longman Dictionary of Contemporary English . 
	</s>
	

	<s id="235">
		 Longman Group Ltd. , Essex , UK . 
	</s>
	

	<s id="236">
		 Rinaldi , Fabio , James Dowdall , Kaarel Kaljurand , Michael Hess , and Diego Mollá . 
	</s>
	

	<s id="237">
		 2003. Exploiting paraphrases in a question answering system . 
	</s>
	

	<s id="238">
		 In The Second International Workshop on Paraphrasing : Paraphrase Acquisition and Applications ( IWP2003 ) , ACL 2003 , 25-32 . 
	</s>
	

	<s id="239">
		 Voorhees , Ellen . 
	</s>
	

	<s id="240">
		 1986. Implementing agglomerative hierarchic clustering algorithms for use in document retrieval . 
	</s>
	

	<s id="241">
		 Information Processing &amp; Management 22/6 : 465-476 . 
	</s>
	


</acldoc>
