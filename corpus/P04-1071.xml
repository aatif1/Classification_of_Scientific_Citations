<?xml version="1.0" encoding="iso-8859-1"?>
<acldoc acl_id="P04-1071">
	

	<s id="1">
		 Wrapping of Trees James Rogers Department of Computer Science Earlham College Richmond , IN 47374 , USA jrogers@cs.earlham.edu Abstract We explore the descriptive power , in terms of syntactic phenomena , of a formalism that extends Tree- Adjoining Grammar ( TAG ) by adding a fourth level of hierarchical decomposition to the three levels TAG already employs . 
	</s>
	

	<s id="2">
		 While extending the descriptive power minimally , the additional level of decomposition allows us to obtain a uniform account of a range of phenomena that has heretofore been difficult to encompass , an account that employs unitary elementary structures and eschews synchronized derivation operations , and which is , in many respects , closer to the spirit of the intuitions underlying TAG-based linguistic theory than previously considered extensions to TAG . 
	</s>
	

	<s id="3">
		 1 Introduction Tree-Adjoining Grammar ( TAG ) 
		<ref citStr="Joshi and Schabes , 1997" id="1" label="CEPF" position="893">
			( Joshi and Schabes , 1997 
		</ref>
		<ref citStr="Joshi et al. , 1975" id="2" label="CEPF" position="920">
			; Joshi et al. , 1975 )
		</ref>
		 is a grammar formalism which comes with a well-developed theory of natural language syntax 
		<ref citStr="Frank , 2002" id="3" label="CEPF" position="1035">
			( Frank , 2002 
		</ref>
		<ref citStr="Frank , 1992" id="4" label="CEPF" position="1050">
			; Frank , 1992 
		</ref>
		<ref citStr="Kroch and Joshi , 1985" id="5" label="CEPF" position="1065">
			; Kroch and Joshi , 1985 )
		</ref>
		 . 
	</s>
	

	<s id="4">
		 There are , however , a number of constructions , many in the core of language , which present difficulties for the linguistic underpinnings of TAG systems , although not necessarily for the implemented systems themselves . 
	</s>
	

	<s id="5">
		 Most of these involve the combining of trees in ways that are more complicated than the simple embedding provided by the tree-adjunction operation . 
	</s>
	

	<s id="6">
		 The most widely studied way of addressing these constructions within TAG-based linguistic theory 
		<ref citStr="Kroch and Joshi , 1987" id="6" label="CEPF" position="1591">
			( Kroch and Joshi , 1987 
		</ref>
		<ref citStr="Kroch , 1989" id="7" label="CEPF" position="1616">
			; Kroch , 1989 
		</ref>
		<ref citStr="Frank , 2002" id="8" label="CEPF" position="1631">
			; Frank , 2002 )
		</ref>
		 has been to assume some sort of multi-component adjoining ( MCTAG 
		<ref citStr="Weir , 1988" id="9" label="CJPF" position="1729">
			( Weir , 1988 )
		</ref>
		 ) , in which elementary structures are factored into sets of trees that are adjoined simultaneously at multiple points . 
	</s>
	

	<s id="7">
		 Depending on the restrictions placed on where this adjoining can occur the effect of such extensions range from no increase in complexity of either the licensed tree sets or the computational complexity of parsing , to substantial increases in both . 
	</s>
	

	<s id="8">
		 In this paper we explore these issues within the framework of an extension of TAG that is conservative in the sense that it preserves the unitary nature of the elementary structures and of the adjunction operation and extends the descriptive power minimally . 
	</s>
	

	<s id="9">
		 While the paper is organized around particular syntactic phenomena , it is not a study of syntax itself . 
	</s>
	

	<s id="10">
		 We make no attempt to provide a comprehensive theory of syntax . 
	</s>
	

	<s id="11">
		 In fact , we attempt to simply instantiate the foundations of existing theory 
		<ref citStr="Frank , 2002" id="10" label="CERF" position="2672">
			( Frank , 2002 )
		</ref>
		 in as faithful a way as possible . 
	</s>
	

	<s id="12">
		 Our primary focus is the interplay between the linguistic theory and the formal language theory . 
	</s>
	

	<s id="13">
		 All of the phenomena we consider can be ( and in practice are 
		<ref citStr="Group , 1998" id="11" label="CEPF" position="2902">
			( Group , 1998 )
		</ref>
		 ) handled ad hoc with feature- structure based TAG ( FTAG , 
		<ref citStr="Vijay-Shanker and Joshi , 1991" id="12" label="CEPF" position="2997">
			( Vijay-Shanker and Joshi , 1991 )
		</ref>
		 ) . 
	</s>
	

	<s id="14">
		 From a practical perspective , the role of the underlying linguistic theory is , at least in part , to insure consistent and comprehensive implementation of ad hoc mechanisms . 
	</s>
	

	<s id="15">
		 From a theoretical perspective , the role of the formal language framework is , at least in part , to insure coherent and computationally well-grounded theories . 
	</s>
	

	<s id="16">
		 Our overall goal is to find formal systems that are as close as possible to being a direct embodiment of the principles guiding the linguistic theory and which are maximally constrained in their formal and computational complexity . 
	</s>
	

	<s id="17">
		 2 Hierarchical Decomposition of Strings and Trees Like many approaches to formalization of natural language syntax , TAG is based on a hierarchical decomposition of strings which is represented by ordered trees . 
	</s>
	

	<s id="18">
		 ( Figure 1. ) These trees are , in essence , graphs representing two relationships—the left-toright ordering of the structural components of the string and the relationship between a component and its immediate constituents . 
	</s>
	

	<s id="19">
		 The distinguishing characteristic of TAG is that it identifies an additional hierarchical decomposition of these trees . 
	</s>
	

	<s id="20">
		 This shows up , for instance when a clause which has the form of a wh-question is embedded as an argument within another clause . 
	</s>
	

	<s id="21">
		 In the Alice DP IP I I’ does like V VP DP t t V DP CP DP who I does DP Alice I^ C’ IP I’ VP d subj-aux inversion . 
	</s>
	

	<s id="22">
		 Figure 2 : Bridge verbs and subj-aux inversion . 
	</s>
	

	<s id="23">
		 of the tree for the embedded clause , an operation known as tree-adjunction . 
	</s>
	

	<s id="24">
		 In effect , the tree for the embedded clause is wrapped around that of the matrix clause . 
	</s>
	

	<s id="25">
		 This process may iterate , with adjunction of arbitrarily many instances of bridge verb trees : form and the canonical configuration . 
	</s>
	

	<s id="26">
		 The Who does Bob believe ...Carol thinks that Alice likes . 
	</s>
	

	<s id="27">
		 ‘’s Bob in the wh-form ( as in the right-hand tree of Figure 1 ) , one of the arguments of the verb is fronted as a wh-word and the inflectional element ( does , in this case ) precedes the subject . 
	</s>
	

	<s id="28">
		 This is generally known in the literature as wh-movement and subj-aux inversion , but TAG does not necessarily assume there is any actual transformational movement involved , only that there is a systematic relationship between the wh- trees mark the position of the corresponding compo- nents in the canonical trees.l When such a clause occurs as the argument of matrix clause between the upper an a bridge verb ( such as think or believe ) it is split , ' This systematic relationship between the wh-form and the with the wh-word appearing to the left of the matrix has been a fundamental component of clause and the rest of the subordinate clause occur- the ring to the right ( Figure 2 ) . 
	</s>
	

	<s id="29">
		 Standardly , TAG ac- like counts analyze this as insertion of the tree for the Figure 1 : Wh-movement an lower portions One of the key advantages of this approach is that the wh-word is introduced into the derivation within the same elementary structure as the verb it is an argument of . 
	</s>
	

	<s id="30">
		 Hence these structures are semantically coherent—they express all and only the structural relationships between the elements of a single functional domain 
		<ref citStr="Frank , 2002" id="13" label="CEPF" position="6307">
			( Frank , 2002 )
		</ref>
		 . 
	</s>
	

	<s id="31">
		 The adjoined structures are similarly coherent and the derivation preserves that coherence at all stages . 
	</s>
	

	<s id="32">
		 Following 
		<ref citStr="Rogers ( 2003 )" id="14" label="CEPF" position="6460">
			Rogers ( 2003 )
		</ref>
		 we will represent this by connecting the adjoined tree to the point at which it adjoins via a third , “tree constituency” relation as in the right hand part of Figure 2 . 
	</s>
	

	<s id="33">
		 This gives us canonical configuration syntactic theories dating back , at least , to the work of Harris in ’50’s . 
	</s>
	

	<s id="34">
		 IP DP Alice VP DP who CP I^ does IP Carol I DPt think V VP C that IP DP Alice I does V VP DP DP who C CP does I I t Carol DP VP IP like t I V think does V DP like t Alice DP IP I does seem V VP I to like V DP VP Bob DP who CP I does Alice DP IP I t seem V VP I to like V VP DP t Figure 3 : Raising verbs . 
	</s>
	

	<s id="35">
		 structures that we usually conceptualize as three- dimensional trees , but which can simply be regarded as graphs with three sorts of edges , one for each of the hierarchical relations expressed by the structures . 
	</s>
	

	<s id="36">
		 Within this context , tree-adjunction is a process of concatenating these structures , identifying the root of the adjoined structure with the point at which it is adjoined.2 The resulting complex structures are formally equivalent to the derivation trees in standard formalizations of TAG . 
	</s>
	

	<s id="37">
		 The derived tree is obtained by concatenating the tree yield of the structure analogously to the way that the string yield of a derivation tree is concatenated to form the derived string of a context-free grammar . 
	</s>
	

	<s id="38">
		 Note that in this case it is essential to identify the point in the frontier of each tree component at which the components it dominates will be attached . 
	</s>
	

	<s id="39">
		 This point is referred to as the foot of the tree and the path to it from the root is referred to as the ( principal ) spine of the tree . 
	</s>
	

	<s id="40">
		 Here we have marked the spines by doubling the corresponding edges of the graphs . 
	</s>
	

	<s id="41">
		 Following 
		<ref citStr="Rogers ( 2002 )" id="15" label="CERF" position="8263">
			Rogers ( 2002 )
		</ref>
		 , we will treat the subject of the clause as if it were “adjoined” into the rest of the clause at the root of the . 
	</s>
	

	<s id="42">
		 At this point , this is for purely theory-internal reasons—it will allow us to exploit the additional formal power we will shortly bring to bear . 
	</s>
	

	<s id="43">
		 It should be noted that it does not represent ordinary adjunction . 
	</s>
	

	<s id="44">
		 The subject originates in the same elementary structure as the rest of the clause , it is just a somewhat richer structure than the more standard tree . 
	</s>
	

	<s id="45">
		 3 Raising Verbs and Subj-Aux Inversion A problem arises , for this account , when the matrix verb is a raising verb , such as seems or appears as in 2Context-free derivation can be viewed as a similar process of concatenating trees . 
	</s>
	

	<s id="46">
		 Alice seems to like Bob Who does Alice seem to like Here the matrix clause and the embedded clause share , in some sense , the same subject argument . 
	</s>
	

	<s id="47">
		 ( Figure 3. ) Raising verbs are distinguished , further , from the control verbs ( such as want or promise ) in the fact that they may realize their subject as an expletive it : It seems Alice likes Bob . 
	</s>
	

	<s id="48">
		 Note , in particular , that in each of these cases the inflection is carried by the matrix clause . 
	</s>
	

	<s id="49">
		 In order to maintain semantic coherence , we will assume that the subject originates in the elementary structure of the embedded clause . 
	</s>
	

	<s id="50">
		 This , then , interprets the raising verb as taking an to an , adjoining at the between the subject and the inflectional element of the embedded clause ( as in the left-hand side of Figure 3 ) . 
	</s>
	

	<s id="51">
		 For the declarative form this provides a nesting of the trees similar to that of the bridge verbs ; the embedded clause tree is wrapped around that of the matrix clause . 
	</s>
	

	<s id="52">
		 For the wh-form , however , the wrapping pattern is more complex . 
	</s>
	

	<s id="53">
		 Since who and Alice must originate in the same elementary structure as like , while does must originate in the same elementary structure as seem , the trees evidently must factor and be interleaved as shown in the right-hand side of the figure . 
	</s>
	

	<s id="54">
		 Such a wrapping pattern is not possible in ordinary TAG . 
	</s>
	

	<s id="55">
		 The sequences of labels occurring along the spines of TAG tree sets must form context- free languages 
		<ref citStr="Weir , 1988" id="16" label="CEPF" position="10559">
			( Weir , 1988 )
		</ref>
		 . 
	</s>
	

	<s id="56">
		 Hence the “center- embedded” wrapping patterns of the bridge verbs and the declarative form of the raising verbs are possible but the “cross-serial” pattern of the wh-form of the raising verbs is not . 
	</s>
	

	<s id="57">
		 Figure 4 : An higher-order account . 
	</s>
	

	<s id="58">
		 CP DP^ IP who IP I DP DP VP who does I does I t Alice CP I V DP VP to seem Alice VP V IP I DP like t t CP I DP V does Alice seem DP who I to VP I t seem DP V VP to I like V VP t V DP like t 4 Higher-order Decomposition One approach to obtaining the more complicated wrapping pattern that occurs in the wh-form of the raising verb trees is to move to a formalism in which the spine languages of the derived trees are TALs ( the string languages derived by TAGs ) , which can describe such patterns . 
	</s>
	

	<s id="59">
		 One such formalism is the third level of Weir’s Control Language Hierarchy 
		<ref citStr="Weir , 1992" id="17" label="CJPN" position="11431">
			( Weir , 1992 )
		</ref>
		 which admits sets of derivation trees generated by CFGs which are filtered by a requirement that the sequences of labels on the spines occur in some particular TAL.3 The problem with this approach is that it abandons the notion of semantic coherence of the elementary structures . 
	</s>
	

	<s id="60">
		 It turns out , however , that one can generate exactly the same tree sets if one moves to a formalism in which another level of hierarchical decomposition is introduced 
		<ref citStr="Rogers , 2003" id="18" label="CEPF" position="11908">
			( Rogers , 2003 )
		</ref>
		 . 
	</s>
	

	<s id="61">
		 This now gives structures which employ four hierarchical relations—the fourth representing the constituency relation encoding a hierarchical decomposition of the third-level structures . 
	</s>
	

	<s id="62">
		 In this framework , the seem structure can be taken to be inserted between the subject and the rest of the like structure as shown in Figure 4 . 
	</s>
	

	<s id="63">
		 Again , spines are marked by doubling 3TAG is equivalent to the second level of this hierarchy , in which the spine languages are Context-Free . 
	</s>
	

	<s id="64">
		 the edges . 
	</s>
	

	<s id="65">
		 The third-order yield of the corresponding derived structure now wraps the third-order like structure around that of the seem structure , with the fragment of like that contains the subject attaching at the third-order “foot” node in the tree-yield of the seem structure ( the ) as shown at the bottom of the figure . 
	</s>
	

	<s id="66">
		 The center-embedding wrapping pattern of these third-order spines guarantees that the wrapping pattern of spines of the tree yield will be a TAL , in particular , the “cross-serial” pattern needed by raising of wh-form structures . 
	</s>
	

	<s id="67">
		 The fourth-order structure has the added benefit of clearly justifying the status of the like structure as a single elementary structure despite of the apparent extraction of the subject along the third relation . 
	</s>
	

	<s id="68">
		 5 Locality Effects Note that it is the to recursion along the third- order spine of the seem structure that actually does the raising of the subject . 
	</s>
	

	<s id="69">
		 One of the consequences of this is that that-trace violations , such as Who does Alice seem that does like . 
	</s>
	

	<s id="70">
		 cannot occur . 
	</s>
	

	<s id="71">
		 If the complementizer originates in the seem structure , it will occur under the . 
	</s>
	

	<s id="72">
		 If it originates in the like tree it will occur in a similar position between the CP and the . 
	</s>
	

	<s id="73">
		 In either case , Figure 5 : Expletive it . 
	</s>
	

	<s id="74">
		 CP IP that C IP DP Alice does I DP it VP I V seem does V DP like Bob the complementizer must precede the raised subject in the derived string . 
	</s>
	

	<s id="75">
		 If we fill the subject position of the seem structure with expletive it , as in Figure 5 , the position in the yield of the structure is occupied and we no longer have to recursion . 
	</s>
	

	<s id="76">
		 This motivates analyzing these structures as to recursion , similar to bridge verbs , rather than to . 
	</s>
	

	<s id="77">
		 ( Figure 5. ) More importantly the presence of the expletive subject in the seem tree rules out super-raising violations such as Alice does appear it seems does like Bob . 
	</s>
	

	<s id="78">
		 No matter how the seem structure is interpreted , if it is to raise Alice then the Alice structure will have to settle somewhere in its yield . 
	</s>
	

	<s id="79">
		 Without extending the seem structure to include the position , none of the possible positions will yield the correct string ( and all can be ruled out on simple structural grounds ) . 
	</s>
	

	<s id="80">
		 If the seem structure is extended to include the , the raising will be ruled out on the assumption that the structure must attach at . 
	</s>
	

	<s id="81">
		 6 Subject-Object Asymmetry Another phenomenon that has proved problematic for standard TAG accounts is extraction from nominals , such as Who did Alice publish a picture of . 
	</s>
	

	<s id="82">
		 Here the wh-word is an argument of the prepositional phrase in the object nominal picture of . 
	</s>
	

	<s id="83">
		 Apparently , the tree structure involves wrapping of the picture tree around the publish tree . 
	</s>
	

	<s id="84">
		 ( See Figure 6. ) The problem , as normally analyzed 
		<ref citStr="Frank , 2002" id="19" label="CEPF" position="15365">
			( Frank , 2002 
		</ref>
		<ref citStr="Kroch , 1989" id="20" label="CEPF" position="15380">
			; Kroch , 1989 )
		</ref>
		 , is that the the publish tree does have the recursive structure normally assumed for auxiliary trees . 
	</s>
	

	<s id="85">
		 We will take a somewhat less strict view and rule out the adjunction of the publish tree simply on the grounds that it would involve attaching a structure rooted in ( or possibly CP ) to a DP node . 
	</s>
	

	<s id="86">
		 The usual way around this difficulty has been to assume that the who is introduced in the publish tree , corresponding , presumably , to the as yet missing DP . 
	</s>
	

	<s id="87">
		 The picture tree is then factored into two components , an isolated DP node which adjoins at the wh-DP , establishing its connection to the argument trace , and the picture DP which combines at the object position of publish . 
	</s>
	

	<s id="88">
		 This seems to at least test the spirit of the semantic coherence requirement . 
	</s>
	

	<s id="89">
		 If the who is not extraneous in the publish tree then it must be related in some way to the object position . 
	</s>
	

	<s id="90">
		 But the identity of who is ultimately not the object of publish ( a picture ) but rather the object of the embedded preposition ( the person the picture is of ) . 
	</s>
	

	<s id="91">
		 If we analyze this in terms of a fourth hierarchical relation , we can allow the who to originate in the picture structure , which would now be rooted in CP . 
	</s>
	

	<s id="92">
		 This could be allowed to attach at the root of the publish structure on the assumption that it is a C-node of some sort , providing the wrapping of its tree-yield around that of the publish . 
	</s>
	

	<s id="93">
		 ( See Figure 6. ) Thus we get an account with intact elementary structures which are unquestionably semantically coherent . 
	</s>
	

	<s id="94">
		 One of the striking characteristics of extraction of this sort is the asymmetry between extraction from the object , which is acceptable , and extraction from the subject , which is not : Who did a picture of illustrate the point . 
	</s>
	

	<s id="95">
		 In the account under consideration , we might contemplate a similar combination of structures , but in this case the picture DP has to somehow migrate up to combine at the subject position . 
	</s>
	

	<s id="96">
		 Under our assumption that the subject structure is attached to the illustrate tree via the third relation , this would require the subject structure to , in effect , have two Alice does it seems does like Bob . 
	</s>
	

	<s id="97">
		 CP CP DP DP DP IP who who IP DP PP IP IP did I t DP VP a picture of P DP t did DP V VP IP DP I PP illustrate the point DP CP IP DP a picture P t V did I VP DP illustrate the point P t Figure 7 : Extraction from subject nominal . 
	</s>
	

	<s id="98">
		 of DP t who V DP PP P of D a picture DP DP illustrate t the point CP DP DP CP DP who who IP CP DP IP IP a picture DP Alice VP DP P of IP did did Alice I I VP t t V DP CP V DP publish publish DP VP DP PP who a picture DP P PP DP P IP P did DP t IP DP Alice I t V apicture publish of DP P t DP of t Figure 6 : Extraction from object nominal . 
	</s>
	

	<s id="99">
		 feet , an extension that strictly increases the generative power of the formalism . 
	</s>
	

	<s id="100">
		 Alternatively , we might assume that the picture structure attaches in the yield of the illustrate structure or between the main part of the structure and the subject tree , but either of these would fail to promote the who to the root of the yield structure . 
	</s>
	

	<s id="101">
		 7 Processing As with any computationally oriented formalism , the ability to define the correct set of structures is only one aspect of the problem . 
	</s>
	

	<s id="102">
		 Just as important is the question of the complexity of processing language relative to that definition . 
	</s>
	

	<s id="103">
		 Fortunately , the languages of the Control Language Hierarchy are well understood and recognition algorithms , based on a CKY-style dynamic programming approach , are know for each level . 
	</s>
	

	<s id="104">
		 The time complexity of the algorithm for the level , as a function of the length of the input ( ) , is 
		<ref citStr="Palis and Shende , 1992" id="21" label="CEPF" position="19218">
			( Palis and Shende , 1992 )
		</ref>
		 . 
	</s>
	

	<s id="105">
		 In the case of the fourth-order grammars , which correspond to the third level of the CLH , this gives an upper bound of . 
	</s>
	

	<s id="106">
		 While , strictly speaking , this is a feasible time complexity , in practice we expect that approaches with better average-case complexity , such as Early- style algorithms , will be necessary if these grammars are to be parsed directly . 
	</s>
	

	<s id="107">
		 But , as we noted in the introduction , grammars of this complexity are not necessarily intended to be used as working grammars . 
	</s>
	

	<s id="108">
		 Rather they are mechanisms for expressing the linguistic theory serving as the foundation of working grammars of more practical complexity . 
	</s>
	

	<s id="109">
		 Since all of our proposed use of the higher-order relations involve either combining at a root ( without properly embedding ) or embedding with finitely bounded depth of nesting , the effect of the higher- dimensional combining operations are expressible using a finite set of features . 
	</s>
	

	<s id="110">
		 Hence , the sets of derived trees can be generated by adding finitely many features to ordinary TAGs and the theory entailed by our accounts of these phenomena ( as expressed in the sets of derived trees ) is expressible in FTAG . 
	</s>
	

	<s id="111">
		 Thus , a complete theory of syntax incorporating them would be ( not necessarily not ) compatible with implementation within existing TAG-based systems . 
	</s>
	

	<s id="112">
		 A more long term goal is to implement a compilation mechanism which will translate the linguistic theory , stated in terms of the hierarchical relations , directly into grammars stated in terms of the existing TAG-based systems . 
	</s>
	

	<s id="113">
		 8 Conclusion In many ways the formalism we have working with is a minimal extension of ordinary TAGs . 
	</s>
	

	<s id="114">
		 Formally , the step from TAG to add the fourth hierarchical relation is directly analogous to the step from CFG to TAG . 
	</s>
	

	<s id="115">
		 Moreover , while the graphs describing the derived structures are often rather complicated , conceptually they involve reasoning in terms of only a single additional relation . 
	</s>
	

	<s id="116">
		 The benefit of the added complexity is a uniform account of a range of phenomena that has heretofore been difficult to encompass , an account that employs unitary elementary structures and eschews synchronized derivation operations , and which is , in many respects , closer to the spirit of the intuitions underlying TAG-based linguistic theory than previously considered extensions to TAG . 
	</s>
	

	<s id="117">
		 While it is impossible to determine how comprehensive the coverage of a more fully developed theory of syntax based on this formalism will be without actually completing such a theory , we believe that the results presented here suggest that the uniformity provided by adding this fourth level of decomposition to our vocabulary is likely to more than compensate for the added complexity of the fourth level elementary structures . 
	</s>
	

	<s id="118">
		 References Robert Evan Frank . 
	</s>
	

	<s id="119">
		 1992. Syntactic Locality and Tree Adjoining Grammar : Grammatical , Acquisition and Processing Perspectives . 
	</s>
	

	<s id="120">
		 Ph.D . 
	</s>
	

	<s id="121">
		 dissertation , Univ . 
	</s>
	

	<s id="122">
		 of Penn. Robert Frank . 
	</s>
	

	<s id="123">
		 2002. Phrase Structure Composition and Syntactic Dependencies . 
	</s>
	

	<s id="124">
		 MIT Press . 
	</s>
	

	<s id="125">
		 The XTAG Research Group . 
	</s>
	

	<s id="126">
		 1998. A lexicalized tree adjoining grammar for english . 
	</s>
	

	<s id="127">
		 Technical Report IRCS-98-18 , Institute for Research in Cognitive Science . 
	</s>
	

	<s id="128">
		 Aravind K. Joshi and Yves Schabes . 
	</s>
	

	<s id="129">
		 1997. Tree- adjoining grammars . 
	</s>
	

	<s id="130">
		 In Handbook of Formal Languages and Automata , volume 3 , pages 69– 123 . 
	</s>
	

	<s id="131">
		 Springer-Verlag . 
	</s>
	

	<s id="132">
		 Aravind K. Joshi , Leon Levy , and Masako Takahashi . 
	</s>
	

	<s id="133">
		 1975. Tree adjunct grammars . 
	</s>
	

	<s id="134">
		 Journal of the Computer and Systems Sciences , 10:136–163 . 
	</s>
	

	<s id="135">
		 Anthony Kroch and Aravind K. Joshi . 
	</s>
	

	<s id="136">
		 1985. The linquistic relevance of tree adjoining grammar . 
	</s>
	

	<s id="137">
		 Technical Report MS-CS-85-16 , Dept. of Computer and Information Sciences . 
	</s>
	

	<s id="138">
		 Anthony S. Kroch and Aravind K. Joshi . 
	</s>
	

	<s id="139">
		 1987. Analyzing extraposition in a tree adjoining grammar . 
	</s>
	

	<s id="140">
		 In Syntax and Semantics , pages 107–149 . 
	</s>
	

	<s id="141">
		 Academic Press . 
	</s>
	

	<s id="142">
		 Vol. 20 . 
	</s>
	

	<s id="143">
		 Anthony Kroch . 
	</s>
	

	<s id="144">
		 1989. Asymmetries in long distance extraction in a tree adjoining grammar . 
	</s>
	

	<s id="145">
		 In Mark Baltin and Anthony Kroch , editors , Alternative Conceptions of Phrase Structure , pages 66–98 . 
	</s>
	

	<s id="146">
		 University of Chicago Press . 
	</s>
	

	<s id="147">
		 Michael A. Palis and Sunil M. Shende . 
	</s>
	

	<s id="148">
		 1992. Upper bounds on recognition of a hierarchy of noncontext-free languages . 
	</s>
	

	<s id="149">
		 Theoretical Computer Science , 98:289–319 . 
	</s>
	

	<s id="150">
		 James Rogers . 
	</s>
	

	<s id="151">
		 2002. One more perspective on semantic relations in TAG . 
	</s>
	

	<s id="152">
		 In Proceedings of the Sixth International Workshop on Tree Adjoining Grammars and Related Frameworks , Venice , IT , May . 
	</s>
	

	<s id="153">
		 James Rogers . 
	</s>
	

	<s id="154">
		 2003. Syntactic structures as multidimensional trees . 
	</s>
	

	<s id="155">
		 Research on Language and Computation , 1(3–4):265–305 . 
	</s>
	

	<s id="156">
		 K. Vijay-Shanker and Aravind K. Joshi . 
	</s>
	

	<s id="157">
		 1991. Unification based tree adjoining grammars . 
	</s>
	

	<s id="158">
		 In J. Wedekind , editor , Unification-based Grammars . 
	</s>
	

	<s id="159">
		 MIT Press , Cambridge , MA . 
	</s>
	

	<s id="160">
		 David J. Weir . 
	</s>
	

	<s id="161">
		 1988 . 
	</s>
	

	<s id="162">
		 Characterizing Mildly Context-Sensitive Grammar Formalisms . 
	</s>
	

	<s id="163">
		 Ph.D . 
	</s>
	

	<s id="164">
		 thesis , University of Pennsylvania . 
	</s>
	

	<s id="165">
		 David J. Weir . 
	</s>
	

	<s id="166">
		 1992. A geometric hierarchy beyond context-free languages . 
	</s>
	

	<s id="167">
		 Theoretical Computer Science , 104:235–261 . 
	</s>
	


</acldoc>
